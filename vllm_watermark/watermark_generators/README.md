# Watermark Generators

This module provides various watermark generation algorithms for embedding watermarks into text generated by language models. The generators are organized into separate modules for better maintainability and clarity.

## Module Structure

- `base.py`: Contains the abstract `WmGenerator` base class and legacy `BaseGenerator`
- `gumbel_generator.py`: Gumbel watermarking using power-law transformation
- `openai_generator.py`: OpenAI-style watermarking method
- `pf_generator.py`: Prefix-free watermarking algorithm
- `maryland_generator.py`: Maryland-style greenlist watermarking
- `vllm_generator.py`: VLLM-specific generator wrapper

## Available Generators

### Base Generator
- **WmGenerator**: Abstract base class for all watermark generators (in `base.py`)
- **BaseGenerator**: Legacy base class for backward compatibility

### Specialized Generators

#### Gumbel Generator (in `gumbel_generator.py`)
- **GumbelGenerator**: Uses power-law transformation r^(1/p) for watermarking

#### OpenAI Generator (in `openai_generator.py`)
- **OpenaiGenerator**: Original OpenAI watermarking using power-law transformation

#### Prefix-Free Generator (in `pf_generator.py`)
- **PFGenerator**: Prefix-free watermarking with exponential transformation

#### Maryland Generator (in `maryland_generator.py`)
- **MarylandGenerator**: Greenlist-based watermarking with logits bias

#### VLLM Generator (in `vllm_generator.py`)
- **VLLMGenerator**: Wrapper for VLLM engine integration

## Usage

### Basic Usage

```python
from vllm_watermark.watermark_generators import GumbelGenerator

# Create a generator
generator = GumbelGenerator(
    model=model,
    tokenizer=tokenizer,
    ngram=2,
    seed=42,
    seeding="hash",
    salt_key=35317,
    payload=0,
)

# Generate watermarked text
prompts = ["Write a story about AI"]
generated_texts = generator.generate(
    prompts=prompts,
    max_gen_len=100,
    temperature=0.8,
    top_p=0.95,
)
```

### Importing Multiple Generators

```python
from vllm_watermark.watermark_generators import (
    GumbelGenerator,
    OpenaiGenerator,
    MarylandGenerator,
)

# Create different generators for comparison
generators = {
    "gumbel": GumbelGenerator(model, tokenizer, **params),
    "openai": OpenaiGenerator(model, tokenizer, **params),
    "maryland": MarylandGenerator(model, tokenizer, gamma=0.5, **params),
}
```

### Advanced Usage with Custom Sampling

```python
# Direct sampling interface
logits = model(input_ids).logits[:, -1, :]  # Last token logits
ngram_tokens = input_ids[:, -ngram:]  # Last ngram tokens

next_token = generator.sample_next(
    logits=logits,
    ngram_tokens=ngram_tokens,
    temperature=0.8,
    top_p=0.95,
)
```

## Parameters

### Common Parameters (defined in base class)
- **model**: The language model to use for generation
- **tokenizer**: The tokenizer corresponding to the model
- **ngram**: Size of n-gram context for seeding (default: 1)
- **seed**: Random seed for reproducibility (default: 0)
- **seeding**: Seeding method ("hash", "additive", "skip", "min") (default: "hash")
- **salt_key**: Salt key for hashing (default: 35317)
- **payload**: Message payload to encode (default: 0)

### Generator-Specific Parameters

#### MarylandGenerator
- **gamma**: Proportion of vocabulary in greenlist (default: 0.5)
- **delta**: Bias strength for greenlist words (default: 1.0)

#### PFGenerator
- **nowm**: Disable watermarking flag (default: False)

## Watermarking Algorithms

### Gumbel Watermarking
Uses power-law transformation: `argmax(r^(1/p))` where `r` is a random vector and `p` is the probability distribution.

### OpenAI Watermarking
Similar to Gumbel but with slightly different implementation details in the power-law transformation.

### Prefix-Free Watermarking
Uses exponential transformation: `argmax(log(p) - log(r))` for better theoretical properties.

### Maryland Watermarking
Partitions vocabulary into greenlist and redlist, adding bias to greenlist words: `logits[greenlist] += delta`.

## Integration with vLLM

The generators are designed to work with the vLLM framework:

```python
from vllm_watermark.core import WatermarkedLLMs

# Create watermarked LLM using the modular generators
wm_llm = WatermarkedLLMs.create(
    llm,
    algo="gumbel",  # Uses GumbelGenerator internally
    seed=42,
    ngram=2
)
```

## Choosing the Right Generator

- **GumbelGenerator**: Good balance of security and text quality
- **OpenaiGenerator**: Original OpenAI approach, well-studied
- **PFGenerator**: Best theoretical properties, prefix-free
- **MarylandGenerator**: Simple and efficient, good for debugging
- **VLLMGenerator**: When you need direct VLLM integration

## Architecture Benefits

The modular architecture provides:
- **Separation of concerns**: Each algorithm has its own file
- **Easy extension**: Add new algorithms without modifying existing code
- **Clean imports**: Import only what you need
- **Better maintainability**: Changes to one algorithm don't affect others
- **Consistent interface**: All generators follow the same API

## Requirements

- torch
- transformers (for tokenizer and model)
- vllm (for VLLMGenerator)
- numpy (for some computations)