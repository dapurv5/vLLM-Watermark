# Watermark Detectors

This module provides various watermark detection algorithms for identifying watermarked text generated by language models. The detectors are organized into separate modules for better maintainability and clarity.

## Module Structure

- `base.py`: Contains the abstract `WmDetector` base class
- `maryland_detectors.py`: Maryland-style detectors (binomial and z-score variants)
- `openai_detectors.py`: OpenAI-style detectors (gamma and z-score variants)
- `pf_detector.py`: Prefix-free watermark detector

## Available Detectors

### Base Detector
- **WmDetector**: Abstract base class for all watermark detectors (in `base.py`)

### Maryland-Style Detectors (in `maryland_detectors.py`)
- **MarylandDetector**: Uses binomial distribution for p-value calculation
- **MarylandDetectorZ**: Uses z-score approximation for p-value calculation

### OpenAI-Style Detectors (in `openai_detectors.py`)
- **OpenaiDetector**: Original OpenAI watermark detector using gamma distribution
- **OpenaiDetectorZ**: OpenAI detector with z-score approximation

### Prefix-Free Detector (in `pf_detector.py`)
- **PFDetector**: Prefix-free watermark detector

## Usage

### Basic Usage

```python
from vllm_watermark.watermark_detectors import MarylandDetectorZ

# Create a detector (parameters should match the generator)
detector = MarylandDetectorZ(
    tokenizer=tokenizer,
    ngram=2,
    seed=42,
    seeding="hash",
    salt_key=35317,
    gamma=0.5,
    threshold=0.05,
)

# Detect watermark in text
result = detector.detect("Your text to analyze here")
print(f"Is watermarked: {result['is_watermarked']}")
print(f"Score: {result['score']}")
print(f"P-value: {result['pvalue']}")
```

### Importing Multiple Detectors

```python
from vllm_watermark.watermark_detectors import (
    MarylandDetectorZ,
    OpenaiDetectorZ,
    PFDetector,
)

# Create multiple detectors for comparison
detectors = {
    "Maryland": MarylandDetectorZ(tokenizer=tokenizer, **params),
    "OpenAI": OpenaiDetectorZ(tokenizer=tokenizer, **params),
    "PF": PFDetector(tokenizer=tokenizer, **params),
}
```

### Advanced Usage

```python
# Get detailed scores for each token
scores = detector.get_scores_by_t(["text1", "text2"])
pvalues = detector.get_pvalues(scores)
aggregated_scores = detector.aggregate_scores(scores)
```

## Parameters

### Common Parameters (defined in base class)
- **tokenizer**: The tokenizer used by the model
- **ngram**: Size of n-gram context (default: 1)
- **seed**: Random seed for reproducibility (default: 0)
- **seeding**: Seeding method ("hash", "additive", "skip", "min") (default: "hash")
- **salt_key**: Salt key for hashing (default: 35317)
- **threshold**: P-value threshold for detection (default: 0.05)

### Detector-Specific Parameters
- **Maryland Detectors**:
  - `gamma`: Proportion of vocabulary in greenlist (default: 0.5)
  - `delta`: Watermark strength parameter (default: 1.0)

## Detection Process

1. **Tokenization**: Text is tokenized into tokens
2. **Scoring**: Each token is scored based on the watermarking algorithm
3. **Aggregation**: Scores are aggregated across the text
4. **P-value Calculation**: Statistical significance is computed
5. **Decision**: Text is classified as watermarked if p-value < threshold

## Choosing the Right Detector

- **MarylandDetector/MarylandDetectorZ**: Good general-purpose detectors using binomial statistics
- **OpenaiDetector/OpenaiDetectorZ**: Use for OpenAI-style watermarking schemes
- **PFDetector**: Use for prefix-free watermarking schemes

The Z-score variants (`MarylandDetectorZ`, `OpenaiDetectorZ`) often provide better performance for large texts by using normal approximations instead of exact distributions.

## Example Output

```python
{
    'is_watermarked': True,
    'score': 2.3456,
    'pvalue': 0.0123
}
```

- `is_watermarked`: Boolean indicating if text is likely watermarked
- `score`: Numerical score (higher values indicate stronger watermark signal)
- `pvalue`: Statistical p-value (lower values indicate higher confidence)

## Requirements

- torch
- numpy
- scipy
- transformers (for tokenizer)
- vllm (for integration)

## Architecture Benefits

The modular architecture provides:
- **Separation of concerns**: Each detector type has its own file
- **Easy extension**: Add new detector types by creating new modules
- **Clean imports**: Import only what you need
- **Better maintainability**: Changes to one detector type don't affect others